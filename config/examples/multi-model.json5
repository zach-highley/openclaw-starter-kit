// Config for users with MULTIPLE models
// Goal: never get locked out when one provider is rate-limited.
// - Primary: Claude Opus (conversation + strategy)
// - Cross-provider fallbacks: Codex → Gemini → Kimi → Local
//
// Apply via `config.patch` (preferred) so you do not clobber existing config.
{
  "agents": {
    "defaults": {
      "model": {
        "primary": "anthropic/claude-opus-4-5",
        "fallbacks": [
          "openai-codex/gpt-5.2",
          "google-gemini-cli/gemini-3-pro-preview",
          "nvidia-nim/moonshotai/kimi-k2.5",
          "ollama/qwen2.5:14b"
        ]
      },
      "compaction": {
        "mode": "safeguard",
        "memoryFlush": {
          "enabled": true,
          "softThresholdTokens": 40000,
          "systemPrompt": "Session nearing compaction. Write all critical context to memory files NOW."
        }
      },
      "contextPruning": {
        "mode": "cache-ttl",
        "ttl": "1h",
        "minPrunableToolChars": 5000,
        "softTrim": {
          "maxChars": 50000,
          "headChars": 2000,
          "tailChars": 5000
        }
      },
      "heartbeat": {
        "every": "55m"
      },
      "subagents": {
        "maxConcurrent": 4,
        "model": {
          "primary": "openai-codex/gpt-5.2",
          "fallbacks": [
            "google-gemini-cli/gemini-3-pro-preview",
            "nvidia-nim/moonshotai/kimi-k2.5",
            "ollama/qwen2.5:14b"
          ]
        }
      },
      "timeoutSeconds": 180
    }
  }
}
